# Cognitive Anomaly Detector

A production-ready network anomaly detection system with **dual detection** (rule-based + ML-based) and **centralized experiment tracking** via MLflow.

## Features

### ‚úÖ Phase 1: ML-Enhanced Detection (COMPLETED)
- **18-feature extraction pipeline**: Statistical, temporal, protocol, port, and payload features
- **Isolation Forest model**: Unsupervised learning for anomaly detection
- **Dual detection system**: ML and rule-based alerts work together
- **MLflow integration**: Experiment tracking and model registry
- **Remote infrastructure**: MLflow server + MinIO S3 storage support
- **Model versioning**: Track, compare, and manage model versions
- **Comprehensive testing**: 36+ tests with high coverage

### üî¨ MLflow Experiment Tracking
- **Centralized tracking**: All experiments logged to remote MLflow server
- **Artifact storage**: Models and training data stored in MinIO S3
- **Model registry**: Version management and deployment tracking
- **Team collaboration**: Shared experiment history and results
- **Production ready**: Remote server setup for scalability

## Quick Start

### 1. Installation

```bash
# Clone repository
git clone https://github.com/RobertoDeLaCamara/DetectorAnomalias.git
cd cognitive-anomaly-detector

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Remote MLflow (Optional)

For centralized tracking with remote MLflow server:

```bash
# Copy environment template
cp .env.example .env

# Edit .env with your credentials
nano .env
```

See [REMOTE_MLFLOW_SETUP.md](REMOTE_MLFLOW_SETUP.md) for detailed setup.

### 3. Train Model

**Option A: With Synthetic Data (fastest)**
```bash
# Generate synthetic training data
python generate_synthetic_data.py

# Train model (completes in seconds)
python train_model.py --from-file data/training/synthetic_baseline.csv --version 1
```

**Option B: With Live Traffic**
```bash
# Collect 60 seconds of real network traffic and train
sudo python train_model.py --duration 60 --version 1
```

### 4. Run Detector

```bash
# Start anomaly detection with trained model
sudo python main.py
```

### 5. Launch Dashboard (Optional)

Visualize anomalies in real-time with the Streamlit dashboard:

```bash
# Launch dashboard
./run_dashboard.sh

# Open browser to http://localhost:8501
```

**Dashboard Features:**
- üè† **Real-time monitoring** with live metrics and charts
- üìä **Historical analysis** with custom date ranges
- üîç **Anomaly inspector** for detailed investigation  
- üåê **Traffic Insights** for network pattern analysis
- ‚öôÔ∏è **System Config** for configuration verification
- üìë **Reports** for incident reporting
- ü§ñ **Model info** showing configuration and features
- üìà **MLflow integration** (backend) for experiment tracking

See [DASHBOARD.md](DASHBOARD.md) for full documentation.

### 6. Security Updates

Recent security fixes include:
- Hardcoded credentials removal
- ReDoS protection
- Command injection prevention
- Path traversal protection

See [SECURITY_FIXES.md](SECURITY_FIXES.md) for details.

### 7. Run with Docker (Recommended)

You can run all components using Docker Compose:

```bash
# Build containers
docker-compose build

# Run Dashboard (http://localhost:8501)
docker-compose up -d dashboard

# Run Detector (background)
docker-compose up -d detector

# Run Trainer (one-off job)
docker-compose run --rm trainer --duration 60
```

See [DOCKER_SETUP.md](DOCKER_SETUP.md) for detailed instructions.

## MLflow Integration

### Local MLflow Setup

```bash
# Initialize MLflow
python setup_mlflow.py

# Train with local tracking
python train_model.py --duration 60 --version 1

# View MLflow UI
mlflow ui --backend-store-uri file://$(pwd)/.mlflow/mlruns
# Open: http://localhost:5000
```

### Remote MLflow Setup

For team collaboration and production deployments:

1. **Configure environment** (`.env`):
   ```bash
   MLFLOW_TRACKING_URI=http://your-mlflow-server:5050
   MLFLOW_S3_ENDPOINT_URL=http://your-minio-server:9000
   AWS_ACCESS_KEY_ID=your_key
   AWS_SECRET_ACCESS_KEY=your_secret
   ```

2. **Test connection**:
   ```bash
   python test_mlflow_connection.py
   ```

3. **Train** (automatically uses remote):
   ```bash
   python train_model.py --duration 60 --version 1
   ```

4. **View results**:
   - MLflow UI: Your configured tracking URI
   - MinIO: Your configured S3 endpoint

## Training Options

```bash
# Basic training
python train_model.py --duration 60 --version 1

# Custom experiment tracking
python train_model.py --duration 60 \
  --experiment-name "production-v1" \
  --run-name "baseline-model" \
  --version 1

# From pre-collected data
python train_model.py --from-file data/training/baseline.csv --version 2

# Disable MLflow for a run
python train_model.py --duration 60 --no-mlflow
```

### Training Parameters

| Parameter | Description | Example |
|-----------|-------------|---------|
| `--duration N` | Collect traffic for N seconds | `--duration 300` |
| `--from-file PATH` | Train from CSV file | `--from-file data/baseline.csv` |
| `--contamination X` | Expected anomaly rate | `--contamination 0.01` |
| `--version V` | Model version number | `--version 2` |
| `--experiment-name` | MLflow experiment name | `--experiment-name prod` |
| `--run-name` | MLflow run name | `--run-name test-1` |
| `--no-mlflow` | Disable MLflow tracking | `--no-mlflow` |

## Detection Usage

### Start Monitoring

```bash
# Monitor with ML model (continuous mode, press Ctrl+C to stop)
sudo python main.py

# Monitor for custom duration (e.g. 120 seconds)
sudo python main.py --duration 120
```

### Output Example

```
Starting network monitoring...
[INFO] ML detector loaded successfully (version 1)
[ALERT] [ML] ML ANOMALY: 192.168.1.50 - Score: -0.234
[ALERT] [RULE] Traffic spike from 192.168.1.100 - Rate: 45.2 pkt/s
[ALERT] [RULE] Uncommon port 8888 from 192.168.1.75

Traffic summary:
IP: 192.168.1.45, Packets: 345
IP: 142.250.110.81, Packets: 182
```

## Configuration

### ML Settings (`src/ml_config.py`)
```python
ML_ENABLED = True                    # Enable/disable ML detection
MIN_PACKETS_FOR_ML = 10              # Min packets before ML inference
ML_ANOMALY_THRESHOLD = 0.0          # Anomaly score threshold (adjusted for sensitivity)
CONTAMINATION = 0.01                 # Expected anomaly rate (1%)
N_ESTIMATORS = 100                   # Number of trees in forest
```

### Rule-Based Settings (`src/config.py`)
```python
THRESHOLD_MULTIPLIER = 2.0           # Traffic spike threshold  
MONITORING_INTERVAL = 60             # Analysis interval in seconds
ICMP_THRESHOLD = 50                  # ICMP flood threshold
PAYLOAD_THRESHOLD = 100              # Large payload threshold
```

## Testing

The project includes a comprehensive test suite covering unit, component, and integration testing.

### Test Categories

| Category | Description | Key Test Files |
|----------|-------------|----------------|
| **Unit Tests** | Validates individual functions and logic | `test_feature_extractor.py`<br>`test_payload_analyzer_fixed.py`<br>`test_logger_setup.py` |
| **Component Tests** | Tests detection engines and ML models | `test_anomaly_detector_new.py`<br>`test_isolation_forest.py` |
| **Integration Tests** | Verifies end-to-end system flow | `test_integration.py`<br>`test_mlflow_integration.py` |

### Running Tests

Run specific test categories or the full suite using `pytest`:

```bash
# 1. Run All Tests
pytest tests/ -v

# 2. Run Core Detection Tests (ML & Rules)
pytest tests/test_anomaly_detector_new.py tests/test_isolation_forest.py -v

# 3. Run Integration Tests (System & MLflow)
pytest tests/test_integration.py tests/test_mlflow_integration.py -v

# 4. Generate Coverage Report
pytest tests/ --cov=src --cov-report=term-missing
```

### Key Test Suites

- **`test_anomaly_detector_new.py`**: Validates the rule-based detection engine (ICMP flood, traffic spikes, port scans).
- **`test_isolation_forest.py`**: Verifies the ML model's training, saving, loading, and prediction logic.
- **`test_integration.py`**: Simulates traffic injection to verify the entire pipeline from packet capture to alert generation.
- **`test_mlflow_integration.py`**: Ensures models are correctly logged, versioned, and retrievable from the MLflow server.

## Project Structure

```
cognitive-anomaly-detector/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ anomaly_detector.py         # Dual detection engine
‚îÇ   ‚îú‚îÄ‚îÄ config.py                   # General configuration
‚îÇ   ‚îú‚îÄ‚îÄ dashboard_config.py         # Dashboard settings
‚îÇ   ‚îú‚îÄ‚îÄ dashboard_data.py           # Dashboard data management
‚îÇ   ‚îú‚îÄ‚îÄ feature_extractor.py        # 18-feature extraction
‚îÇ   ‚îú‚îÄ‚îÄ isolation_forest_detector.py # ML model implementation
‚îÇ   ‚îú‚îÄ‚îÄ logger_setup.py             # Logging setup
‚îÇ   ‚îú‚îÄ‚îÄ ml_config.py                # ML settings
‚îÇ   ‚îú‚îÄ‚îÄ mlflow_config.py            # MLflow configuration
‚îÇ   ‚îú‚îÄ‚îÄ model_trainer.py            # Training pipeline with MLflow
‚îÇ   ‚îú‚îÄ‚îÄ payload_analyzer.py         # Pattern matching
‚îÇ   ‚îú‚îÄ‚îÄ security_config.py          # Security settings
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                    # Shared utilities
‚îÇ   ‚îî‚îÄ‚îÄ visualization_utils.py      # Plotting helpers
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_feature_extractor.py   # Feature tests
‚îÇ   ‚îú‚îÄ‚îÄ test_integration.py         # E2E tests
‚îÇ   ‚îú‚îÄ‚îÄ test_isolation_forest.py    # ML model tests
‚îÇ   ‚îú‚îÄ‚îÄ test_mlflow_integration.py  # MLflow tests
‚îÇ   ‚îî‚îÄ‚îÄ test_payload_analyzer.py    # Pattern tests
‚îú‚îÄ‚îÄ data/                           # Data directory
‚îú‚îÄ‚îÄ models/                         # Local model storage
‚îú‚îÄ‚îÄ .env.example                    # Environment template
‚îú‚îÄ‚îÄ API.md                          # API documentation
‚îú‚îÄ‚îÄ CONTRIBUTING.md                 # Contribution guidelines
‚îú‚îÄ‚îÄ DASHBOARD.md                    # Dashboard documentation
‚îú‚îÄ‚îÄ DOCKER_SETUP.md                 # Docker setup guide
‚îú‚îÄ‚îÄ Dockerfile                      # Docker configuration
‚îú‚îÄ‚îÄ INSTALL.md                      # Installation guide
‚îú‚îÄ‚îÄ Jenkinsfile                     # CI/CD pipeline
‚îú‚îÄ‚îÄ LICENSE                         # License file
‚îú‚îÄ‚îÄ QUICKSTART.md                   # Quick start guide
‚îú‚îÄ‚îÄ README.md                       # Project overview
‚îú‚îÄ‚îÄ REMOTE_MLFLOW_SETUP.md          # Remote setup guide
‚îú‚îÄ‚îÄ SECURITY.md                     # Security policy
‚îú‚îÄ‚îÄ dashboard.py                    # Dashboard implementation
‚îú‚îÄ‚îÄ docker-compose.yml              # Docker Compose configuration
‚îú‚îÄ‚îÄ generate_synthetic_data.py      # Synthetic data generator
‚îú‚îÄ‚îÄ inject_synthetic_traffic.py     # Traffic injector
‚îú‚îÄ‚îÄ main.py                         # Detection entry point
‚îú‚îÄ‚îÄ promote_latest.py               # Model promotion script
‚îú‚îÄ‚îÄ requirements.txt                # Dependencies
‚îú‚îÄ‚îÄ run_dashboard.sh                # Dashboard launcher
‚îú‚îÄ‚îÄ setup_mlflow.py                 # MLflow initialization
‚îú‚îÄ‚îÄ test_mlflow_connection.py       # Connectivity test
‚îî‚îÄ‚îÄ train_model.py                  # Training CLI
```

## How It Works

### Dual Detection System

**1. Rule-Based Detection**
- Traffic rate spikes (2x average)
- ICMP flood detection
- Uncommon port monitoring
- Large payload detection (> 100 bytes)
- Malicious pattern matching (SQL injection, XSS, shell commands)

**2. ML-Based Detection (Isolation Forest)**

**Feature Extraction** (18 features per IP):
- **Statistical**: packet/byte rates, sizes, variance (6 features)
- **Temporal**: inter-arrival times, burst rates, duration (4 features)
- **Protocol**: TCP/UDP/ICMP ratios (3 features)
- **Port**: unique ports, uncommon port ratio (2 features)
- **Payload**: entropy, size statistics (3 features)

**Anomaly Scoring**:
- Isolation Forest assigns scores (-1 to 1)
- Lower scores = more anomalous behavior
- Threshold-based alerting (configurable)

**Model Lifecycle**:
1. Train on baseline normal traffic
2. Track experiments in MLflow
3. Version models in registry
4. Load for real-time detection
5. Continuous monitoring and improvement

## MLflow Features

### Experiment Tracking
- **Parameters**: contamination, n_estimators, n_features
- **Metrics**: training_time, anomaly_rate, score statistics
- **Artifacts**: model files, training data, feature lists
- **Tags**: project, model_type, framework

### Model Registry
- **Versioning**: Automatic version management
- **Stages**: Development, Staging, Production
- **Lineage**: Track model origins and training data
- **Comparison**: Compare multiple model versions

### Remote Infrastructure
- **MLflow Server**: Centralized tracking and registry
- **MinIO Storage**: S3-compatible object storage for artifacts
- **Team Collaboration**: Shared experiment history
- **Production Ready**: Scalable deployment

## Roadmap

- ‚úÖ **Phase 1: Foundation** (COMPLETED)
  - Isolation Forest implementation
  - Feature extraction pipeline
  - MLflow integration
  - Remote server support
  - Model versioning

- ‚è≥ **Phase 2: Advanced Models**
  - LSTM networks for sequential analysis
  - Autoencoder for unsupervised detection
  - Ensemble meta-learning
  
- üìã **Phase 3: Production Features**
  - ‚úÖ **Real-time dashboard** (COMPLETED)
  - Automated retraining
  - A/B testing framework
  - Alert management system

## Documentation

- [DOCKER_SETUP.md](DOCKER_SETUP.md) - Docker container setup guide
- [DASHBOARD.md](DASHBOARD.md) - Streamlit visualization dashboard guide
- [REMOTE_MLFLOW_SETUP.md](REMOTE_MLFLOW_SETUP.md) - Remote MLflow/MinIO setup
- [INSTALL.md](INSTALL.md) - Detailed installation guide
- [QUICKSTART.md](QUICKSTART.md) - Quick start guide
- [AI_ML_Enhancement_Proposal.md](AI_ML_Enhancement_Proposal.md) - Full roadmap

## Requirements

- Python 3.8+
- Root/sudo access (for packet capture)
- Network interface access
- Optional: Remote MLflow server + MinIO for team usage

### Dependencies
- `scapy>=2.5.0` - Packet capture
- `scikit-learn>=1.3.0` - ML algorithms
- `mlflow>=2.9.0` - Experiment tracking
- `boto3>=1.28.0` - S3/MinIO storage
- `numpy`, `pandas` - Data processing
- `streamlit>=1.28.0` - Real-time dashboard
- `plotly>=5.17.0` - Interactive visualizations
- `altair>=5.1.0` - Declarative charting

## License

MIT License - See LICENSE file

## Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Add tests for new features
4. Submit a pull request

## Support

For issues or questions:
- GitHub Issues: [Report bugs or request features]
- Documentation: See docs/ directory
- MLflow UI: View experiment results and model versions
